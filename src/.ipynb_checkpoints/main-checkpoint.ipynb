{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data..\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import logging\n",
    "import torch\n",
    "from torchtext import data\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "import io\n",
    "import time\n",
    "import sys\n",
    "import model\n",
    "import datahelper\n",
    "LOGGER = logging.getLogger(\"toxic_dataset\")\n",
    "\n",
    "\n",
    "\n",
    "device = -1 # 0 for gpu, -1 for cpu\n",
    "batch_size = 16\n",
    "test_mode = 0  # 0 for train+test 1 for test\n",
    "embedding_dim = 100\n",
    "hidden_dim = 64\n",
    "epochs = 4\n",
    "\n",
    "\n",
    "\n",
    "print('Reading data..')\n",
    "normalize_pipeline = data.Pipeline(convert_token=datahelper.normalizeString)\n",
    "ID = data.Field(sequential=False, batch_first=True)\n",
    "TEXT = data.Field(sequential=True, lower=True, eos_token='<EOS>', init_token='<BOS>',\n",
    "                  pad_token='<PAD>', fix_length=None, batch_first=True, preprocessing=normalize_pipeline)\n",
    "LABEL = data.Field(sequential=False, batch_first=True)\n",
    "\n",
    "\n",
    "train = data.TabularDataset(\n",
    "        path='../data/train.tsv', format='tsv',\n",
    "        fields=[('Id', ID), ('Label', LABEL), ('Review', TEXT)], skip_header=True)\n",
    "test = data.TabularDataset(\n",
    "        path='../data/test.tsv', format='tsv',\n",
    "        fields=[('Id', ID), ('Review', TEXT)], skip_header=True)\n",
    "\n",
    "\n",
    "TEXT.build_vocab(train.Review,test.Review)\n",
    "ID.build_vocab(train.Id, test.Id)\n",
    "LABEL.build_vocab(train.Label, test.Label)\n",
    "\n",
    "\n",
    "print('Build Finished.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_iter = data.BucketIterator(dataset=train, batch_size=batch_size, sort_key=lambda x: len(x.Review), device=device, repeat=False)\n",
    "test_iter = data.Iterator(dataset=test, batch_size=batch_size, device=device, shuffle=False, repeat=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dl = datahelper.BatchWrapper(train_iter, \"Review\", [\"Id\", \"Label\"])\n",
    "test_dl = datahelper.BatchWrapper(test_iter, \"Review\", [\"Id\"])\n",
    "print('Reading data done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "  2.0000e+00  4.2830e+03  1.9350e+03  ...   2.3442e+04  3.0000e+00  1.0000e+00\n",
       "  2.0000e+00  1.9800e+03  4.2000e+01  ...   1.6149e+05  3.0000e+00  1.0000e+00\n",
       "  2.0000e+00  7.2000e+01  1.6830e+03  ...   2.1580e+03  3.0000e+00  1.0000e+00\n",
       "                 ...                   â‹±                   ...                \n",
       "  2.0000e+00  4.3430e+03  3.6198e+04  ...   5.0000e+00  2.7759e+04  3.0000e+00\n",
       "  2.0000e+00  1.3799e+05  1.7096e+04  ...   8.4360e+03  1.8000e+01  3.0000e+00\n",
       "  2.0000e+00  1.0600e+02  2.3000e+01  ...   4.9100e+02  1.1880e+03  3.0000e+00\n",
       " [torch.LongTensor of size 16x130], Variable containing:\n",
       "  29979      2\n",
       "    499      1\n",
       "  30440      1\n",
       "   9760      1\n",
       "  22513      2\n",
       "  30111      2\n",
       "  14624      2\n",
       "  20991      2\n",
       "  41146      1\n",
       "   2968      2\n",
       "  29242      1\n",
       "   2382      2\n",
       "  38307      2\n",
       "  41220      2\n",
       "  38982      2\n",
       "   5564      1\n",
       " [torch.FloatTensor of size 16x2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "print('Initialing model..')\n",
    "MODEL = model.lstm_model(len(TEXT.vocab), embedding_dim, hidden_dim, batch_size)\n",
    "if device == 0:\n",
    "    MODEL.cuda()\n",
    "\n",
    "# Train\n",
    "if not test_mode:\n",
    "    loss_function = nn.NLLLoss()\n",
    "    optimizer = optim.Adam(MODEL.parameters(), lr=1e-3)\n",
    "    print('Start training..')\n",
    "\n",
    "    train_iter.create_batches()\n",
    "    batch_num = len(list(train_iter.batches))\n",
    "\n",
    "    for i in range(epochs) :\n",
    "        avg_loss = 0.0\n",
    "        train_iter.init_epoch()\n",
    "        batch_count = 0\n",
    "        for batch, label in train_dl:\n",
    "            batch_start = time.time()\n",
    "            y_pred,_ = MODEL(batch)\n",
    "            loss = loss_function(y_pred, label)\n",
    "            MODEL.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            batch_count += 1\n",
    "            batch_end = time.time()\n",
    "            print('Finish {}/{} batch, {}/{} epoch. Time consuming {}s, loss is {}'.format(batch_count, batch_num, i+1, epochs, round(batch_end - batch_start, 2), float(loss)))\n",
    "        torch.save(MODEL.state_dict(), 'model' + str(i+1)+'.pth')           \n",
    "\n",
    "# Test\n",
    "print('Start predicting...')\n",
    "MODEL.load_state_dict(torch.load('model{}.pth'.format(epochs)))\n",
    "\n",
    "f1 = open('submission.csv','w')\n",
    "f1.write('\"id\",\"sentiment\"'+'\\n')\n",
    "final_res = []\n",
    "\n",
    "for batch in iter(test_dl):\n",
    "    hidden = MODEL.init_hidden()\n",
    "    y_pred,_ = MODEL(batch)\n",
    "    pred_res = y_pred.data.max(1)[1].cpu().numpy()\n",
    "    final_res.extend(pred_res)\n",
    "\n",
    "print('Prediction done...')\n",
    "for idx, res in enumerate(final_res):\n",
    "    text_id = test_iter.dataset.examples[idx].Id\n",
    "    f1.write(text_id + ',' + str(res)+'\\n')\n",
    "print('Results dumping done...')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
